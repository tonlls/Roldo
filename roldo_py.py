# -*- coding: utf-8 -*-
"""Roldo.py

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1MN7ATCCTtSro6VyEPo4wcfSV2aKaIPoe
"""

import numpy as np
import scipy as sc
import matplotlib.pyplot as plt

from sklearn.datasets import make_circles

import json
p=136
json_d=open("features_extracted.json", "r").read()
nX=[]
nY=[]

data=json.loads(json_d)
out_d=[]
N=470
nR=[]
for key, value in data.items():
    temp = [key,{int(k):v for k,v in value.items()}]
    out_d.append(temp)
print(out_d)
for it in range(N):
  item=[]
  for i in range(136):
    item.append(out_d[i][1][it])
  nY.append(out_d[136][1][it])
  nR.append(out_d[136][1][it])
  nX.append(item)
  #nY.append()
nX=np.array(nX)
import random
#for i in range(N):
#  nY.append(random.choice([0,1]))
nY=np.array(nY)
nY=nY[:,np.newaxis]

def sigmoid(x):
  return 1/(1+np.e**(-x))
def der_sigmoid(x):
  return x*(x-1)
def relu(x):
  return np.maximum(0,x)
def der_relu(x):
  return 1/(1+np.e**(-x))
fun=sigmoid
der_fun=der_sigmoid

#sigm=(lambda x:1/(1+np.e**(-x)),
#      lambda x:x*(1-x))
#relu=lambda x:np.maximum(0,x)
#_x=np.linspace(-5,5,100)
#plt.plot(_x,relu(_x))

#classe capa de red

class Neural_layer(object):
  def __init__(self,n_conn,n_neur,b=None,w=None):
    self.act_f=fun
    self.der_act_f=der_fun

    self.n_conn=n_conn
    self.n_neur=n_neur
    self.b=np.random.rand(1,n_neur)*2-1 if b==None else b
    self.w=np.random.rand(n_conn,n_neur)*2-1 if w==None else w

class Neural_net():
  def __init__(self,topology):
    self.layers=[]
    for l,layer in enumerate(topology[:-1]):
      self.layers.append(Neural_layer(topology[l],topology[l+1]))
  def serialize(self,file='datamodel.dat'):
    f=open(file,'wb')
    pickle.dump(self,f)
  @staticmethod
  def deserialize(file='datamodel.dat'):
    f=open(file,'rb')
    return pickle.load(f)

topology=[p,200,300,200,1]
neural_net=Neural_net(topology)
cost=(lambda Yp,Yr:np.mean((Yp-Yr)**2),
      lambda Yp,Yr:(Yp-Yr))
         
def train(neural_net,X,Y,cost,lr,train=True,save=True):
  if neural_net==None :
    neural_net=Neural_net.deserialize()
  out=[(None,X)]
  #forward pass
  for l,layer in enumerate(neural_net.layers):
    z=out[-1][1] @ neural_net.layers[l].w+neural_net.layers[l].b
    a=neural_net.layers[l].act_f(z)
    out.append((z,a))
  if train:
    #backward pass
    deltas=[]
    for l in reversed(range(0,len(neural_net.layers))):
      z=out[l+1][0]
      a=out[l+1][1]
      if l==len(neural_net.layers)-1:
        deltas.insert(0,cost[1](a,Y)*neural_net.layers[l].der_act_f(a))
      else:
        deltas.insert(0,deltas[0]@_W.T*neural_net.layers[l].der_act_f(a))
      _W=neural_net.layers[l].w
      #gradient descent
      neural_net.layers[l].b=neural_net.layers[l].b-np.mean(deltas[0],axis=0,keepdims=True)*lr
      neural_net.layers[l].w=neural_net.layers[l].w-out[l][1].T@deltas[0]*lr
    if save:
      neural_net.serialize()
  return out[-1][1]
def predict(neural_net,X,Y,cost):
  return train(neural_net,X,Y,cost,0.5,False)

import time
from IPython.display import clear_output
import pickle
neural_n = Neural_net(topology)

loss = []

for i in range(100000):

  # Entrenamos a la red:
#  pY = train(None, nX, nY, cost, lr=0.035)
  pY = train(neural_n, nX, nY, cost, lr=0.000003)


  if i % 25 == 0:
    
    loss.append(cost[0](pY,nY))
    plt.plot(range(len(loss)),loss)
    clear_output(wait=True)

    plt.show()
    print(loss[-1])
o=0
for i in range(N):
  v=train(neural_n,[nX[i]],[nY[i]],cost,0,False)[0][0]
#  v=train(None,[nX[i]],[nY[i]],cost,0,False)[0][0]

  if round(v)==int(nR[i]):
    o+=1
  print(v,round(v),int(nR[i]))
print(str(o)+'/'+str(N))